# 데이터 통합

조직의 서비스와 시스템에 필요한 모든 데이터를 사용할 수 있게 하는 것

효율적으로 데이터를 사용한다는 건 매슬로우의 욕구단계설을 따르는 것과 같다.

다음은 매슬로우 욕구단계설과 유사한 데이터 사용계층을 나타낸 것

- 자동화
- 이해
- 의미
- 취득/수집

계층의 밑부분은 모든 관련 데이터를 붙잡아서 적절한 처리 환경에 입력하는 행위를 가리킨다. 데이터는 일정한 방법으로 가공되어 쉽게 읽고 처리할 수 있어야 한다. 일관된 방향으로 데이터를 포착한 다음에는, 인프라에서 여러 가지 방법으로 데이터를 처리한다.

데이터와 처리 두 가지가 가능해야 그 다음 단계(훌륭한 데이터 ㅓ모델과 일관적이고 이해가 쉬운 의미 부여 등)로 진행할 수 있다.

궁극적으로는 더욱 정교한 처리(향성된 시각화, 리포팅, 알고리즘적 처리와 예측)를 할 수 있는 경지에 이르게 된다.

## 데이터 통합을 어렵게 만드는 두 가지

### 발생한 사건things that happen 기반 이벤트 데이터

오늘 날의 이벤트 데이터는 현재 상태things that are보다는 발생한 사건을 기반으로 기록한다.

웹에서는 데이터 센터 규모의 기계를 모니터링 및 운영하는데 필요한 머신 레벨의 이벤트, 통계치 뿐만 아니라 사용자의 활동을 로깅한다.

재무 데이터, RFID와 같은 실물 추적 이벤트 장치, IoT 등의 물리적인 기기를 디지털 세계와 연결하려는 흐름도 연관되어 있다.

이벤트 데이터는 트랜잭션 데이터와 비교하면 계산 차구order of magnitude가 몇 단계 높으므로 기존 데이터 통합 방식과는 근본부터가 다르다.

### 전문 데이터 시스템 폭증

OLAP, 검색, 간단한 온라인 스토리지, 일괄 처리, 그래프 분석 등에 특화된 솔루션을 통한 좀 더 다양한 데이터를 더욱 많은 시스템으로 가져가고 싶은 욕심

## 로그 구조의 데이터 흐름

시스템 간 데이터 흐름을 다루기 위한 데이터 구조가 로그라면 데이터를 모두 취합하여 실시간 구독이 가능하도록 중앙 로그에 넣는다.

로그는 Pub-Sub 메시징에 사용된다. Publisher가 로그를 덧붙이면 각 구독자들은 자신의 로그 포지션을 유지하면서 독립적으로 읽기를 할 수 있다.

또한 로그는 데이터 생산 시점과 소비 시점을 비동기화하기 위한 버퍼 기능도 한다.

구독 시스템에 장애가 발생하거나 보수 작업을 하느라 가도이 일시 중단되었을 때 복구가 완료되면 중단되었던 시간만큼 따라잡아야 하는데, 시스템마다 컨트롤 가능한 데이터 소비 속도가 제각각이다.

출처가 되는 데이터 소스와 로그 모두 다수의 데이터 목적지 시스템에 대해서는 전혀 알 필요가 없으므로, 파이프라인을 변경하지 않고도 데이터 소비 시스템의 추가/삭제도 가능한 것이다.

로그를 지속성durability이 보장된, 엄격한 정렬 개념을 갖춘 Atomic broadcast라 불리는 메시징 시스템의 한 유형으로 생각할 수도 있다.

## 링크드인의 데이터 통합

링크드인의 주요 데이터 시스템

- Search
- Social graph
- Voldemort(key-value store)
- Espresso(document store)
- Recommendation engine
- OLAP query engine
- Hadoop
- Terradata
- Ingraphs(Graph monitoring and metrics)
- Newsfeed(Homepage update system)

### 처음

데이터버스databus 프로덕트를 개발해 초기 오라클 테이블 상부에 로그 캐싱 기능을 추상화시켜 데이터베이스에서 발생한 변경 사항을 수신할 수 있었고, 소셜 그래프와 검색 인덱스 서비스에 데이터를 제공할 수 있었음

하지만 오라클에서의 데이터 웨어하우스 처리는 대부분 비가역적nonreversable인 데다 리포팅에 특화디어 있었기 때문에 운영 환경에서 하둡을 이요한 배치 처리에는 잘 맞지 않았음

결국 소스 데이터 베이스와 로그 파일을 통한 키-값 저장소에 데이터를 적재하는 파이프라인을 새로 구현함

파이프라인을 여러 대 기계에서 돌아갈 수 있도록 조정, 모니터링, 테스팅, 유지 보수하는데 전체 개발 프로젝트의 많은 비중을 차지 했고, 데이터 소스가 하나 추가될 댸마다 수많은 에러와 실패가 발생함

이러한 과정에서 발견한 생각들은

1. 신규 처리 시스템(하둡)에서 데이터를 사용할 수 있게 처리만 해주어도 수많은 새로운 가능성을 발견할 수 있었음. 이전에 힘들던 새 데이터 연산이 가능해지고, 과거 특정 시스템에 묶여 있었던 수 많은 데이터 조각들을 한데 모아 새로운 제품 개발과 분석에 활용할 수 있게 됨

2. 데이터 파이프라인이 탄탄해야 확실한 데이터 적재가 가능하다. 필요한 데이터 구조를 모두 손에 넣은 상태라면 하둡이 완전히 자동으로 데이터를 적재할 수 있었고 데이터 소스를 새로 추가하거나 스킴을 변경하더라도 더 이상의 수작업은 필요 없었다.
> 데이터는 HDFS로, Hive 테이블은 새로운 데이터 소스 컬럼에 맞게 자동생성되기 때문

3. 지속적으로 낮은 데이터 커버리지

수십 개 데이터 시스템과 저장소에 대해 각각 소스와 목적지 별로 데이터 적재를 일일이 조정한다는 건 가능할 것 같지 않았다. 각 시스템을 모조리 파이프라인으로 연결하면 데이터 전송 관점에서 소스인 동시에 타겟이므로 O(n^2) 파이프라인이 되기 때문

### 중앙 허브를 가진 아키텍처

데이터 소비 시스템과 데이터 소스 간의 분리를 위해 소비 시스템을 모두 단일한 데이터 저장소에 통합시켜 전체 소스 데이터를 바라볼 수 있게 하는 것

활동 데이터activity data를 대상으로 중앙 파이프라인 역할을 하면서 하둡에서 데이터를 배포하거나 데이터를 모니터링 하는 등 다양한 용도로 쓸 수 있는 장치가 필요해 카프카Kafka를 개발

## ETL과 데이터웨어하우스와의 관계

데이터 중심적인 조직에서 순수한 통합 데이터와 데이터 웨어하우스 간 결합도가 높은 것이 가장 큰 문제다.

데이터 웨어 하우스는 배치 쿼리 인프라의 한 부류로서, 갖가지 유형의 리포팅, 애드혹 분석ad-hoc analysis, 쿼리 내용이 단순한 카운팅, 집합, 필터링에는 잘 맞는다.

그러나 실시간 피드(처리, 검색 인덱싱, 모니터링 시스템 등)를 요구하는 시스템에서 배치 시스템이 완전한 순수 데이터를 보관하는 유일한 저장소가 될 수는 없다.

ETL은 두 가지 종류로 나뉜다.

- 사내 시스템 내에 존재하는 데이터를 끌어내서 시스템에 특정한system-specific 무의미함nonsense을 제거하는 데이터 추출과 정리cleanup 프롯세스
- 관계형 데이터베이스의 타입 체계에 맞춰진 스타 스키마star-schema, 눈송이 스키마snowflake-schema로 강제 변환된 고성능 컬럼 포맷으로 나뉜 데이터 웨어 하우스 쿼리에 맞게 데이터 구조를 조정

문제는 이 두가지를 융합해 다른 실시간 저장소 시스템의 인덱싱과 신속한 처리를 위해 순수한 통합 데이터 저장소는 실시간으로 사용할 수 있어야 한다.

## ETL과 조직 확장성

데이터를 만들어내는 쪽에서는 데이터 웨어 하우스에서 자신들의 데이터를 어떻게 쓰든지 별 관심이 없고, 그러다 보니 추출하기 곤란하거나 가용한 형태로 변환하기 위해 아주 무겁고 조정하기 힘든 과정을 거쳐야 하는 데이터만 양산

결국 불규칙한 데이터 커버리지, 취약한 데이터 흐름, 더딘 변경 작업 등으로 이어짐

데이터를 생성하는 쪽에서는 이 파이프라인에 데이터를 통합시켜 구조화된 데이터 피드를 제공할 책임이 있음

데이터를 추출하여 구조화된 형식으로 변환 후 중앙 파이프라인에 전송하는 문제를 시스템 설계/구현 일부분으로서 반드시 고려해야 한다

이러한 방법을 통해 데이터 웨어하우스 팀원은 저장 시스템의 신규 추가 업무에서 벗어날 수 있고, 중앙 로그에서 구조화된 데이터 피드를 적재하고 특정 시스템에 맞는 변환 작어버 등 자잘한 문제들만 처리하면 된다.

균일하고 구조화된 데이터 피드를 구축한 회사는 새 시스템을 들여와 간단히 파이프라인에 배관 공사만 끝내면 모든 데이터에 접근할 수 있다.

## 데이터 변환 시점

- (베스트) 데이터 생성 측에서 전사 로그에 데이터를 추가하기 전 수행
- 로그에서 실시간으로 수행(변환된 로그를 새로 생성)
- 목적지 데이터 시스템에 적재하는 과정 일부로 수행

데이터를 로그에 내보내기 전 정제 과정을 마치는 것이 걷어내야 할 부분을 걷어내고 정규화된canonical 형태의 데이터를 보장 할 수 있기 때문에 가장 좋다. 변환 로직은 손실이 없고loseless 가역적reversible이어야 한다.

실시간 환경에서 값이 부가되는value-added 변환은 원천 로그 피드raw log feed를 후처리post-processing 하는 식으로 이루어져야 한다.

이벤트 데이터를 세션화sessionization 한다든지, 다른 일반 파생 필드를 추가할 수도 있을 것이다.

원래 로그는 그대로 남아 있는 상태에서 이렇게 실시간으로 처리하면 증강됨augmented 데이터가 포함된 파생 로그가 만들어진다.

특정 목적지 시스템에만 해당되는 데이터 통합은 적재 프로세스의 일부로 수행되어야 한다. 데이터 웨어하우스에서 분석과 리포팅을 하려고 특정한 스타 스키마나 눈송이 스키마로 데이터 변환을 하는 것을 생각하면 된다.

전통적인 ETL 처리와 자연스레 겹치는 이 단계는 훨씬 순수하고 더욱 균일한 스트림 세트에 대해 수행되며, 아주 단순화되어야 한다.

## 시스템 간 결합도 낮춤

웹 환경에서의 텍스트 파일을 통한 로그 접근 방식은 배치 ETL과 같이 데이터 흐름data-flow이 데이터 웨어하우스의 능력capability과 처리 스케줄에 영향을 받는다는 점이다.

따라서 로그 중심적인 방식으로 이벤트 데이터 처리 시스템을 구축하여, 카프카를 중앙의 다중 구독자multisubscriber 이벤트 로그로 삼았고, 특정 유형의 액션에 대한 고유 속성을 담고 있는 수백 가지 이벤트 타입을 정의 함(페이지 뷰, 광고 임프레션, 검색, 서비스 호출, 애플리케이션 예외 등을 모두 포함)

### 이러한 구조의 장점

채용 정보 페이지에 채용 정보를 게시하는 간단한 이벤트를 생각해보자.

이러한 페이지에 다음과 같은 시스템들을 통합할 수 있다.

- 오프라인으로 처리하기 위해 데이터를 하둡과 데이터 웨어하우스로 전송해야 한다.
- 보안 시스템은 뷰를 카운트해서 유저가 무단으로 내용을 퍼가지는 않는지 확인
- 페이지 뷰를 취합해서 채용 정보 게시자의 분석 페이지에 표시
- 채용 추천 시스템은 똑같은 채용 정보가 계속해서 보이면 안되므로 뷰를 기록해서 같은 유저에 대한 채용 추천의 임프레션을 적절히 제한
- 모니터링 시스템은 특정 채용 정보의 표시 비율과 지원율을 추적해 시스템이 정상적으로 운영되고 있는 지 확인

이벤트 구동 방식으로 접근한다면, 채용 정보 표시 페이지는 단지 채용 정보를 문제없이 보여주고 관련 속성(일자리, 뷰어 등) 및 기타 유용한 정보를 기록하는데 전념하면 된다.

다른 유관 시스템들(추천, 보안, 채용 정보 게시자 분석, 데이터웨어하우스)은 피드를 구독해서 각자의 역할에 충실하면 된다.

채용 정보 표시 페이지의 코드는 이 시스템들의 존재를 신경 쓸 필요가 없고, 새로운 데이터 소비 시스템을 추가할 때에도 전혀 변경되지 않는다.

## 로그 확장

분산 시스템을 하는 사람들은 분산 로그를 종종 느리고 무거운 추상체라고 생각하는 경향이 있다.

대량의 데이터 스트림을 기록하는 데 초점을 두고 세심하게만 구현한다면 꼭 그렇지는 않다.

링크드인의 카프카 클러스터는 하루에 수천억 개의 메시지가 쓰인다.

카프카에 몇 가지 트릭을 사용하면 이 정도 규모의 서비스가 지탱 가능하다.

- 로그를 파티셔닝하여 각 파티션이 다른 파티션과 독립적으로 작동하게 한다.
  - 작성자는 메시지 할당의 제어권을 특정 파티션에게 넘기는데, 대부분 유저 ID 같은 데이터를 키로하여 파티션을 고른다. 샤드shard 사이에 별도 조정을 하지 않아도 파티셔닝으로 로그를 추가할 수 있고, 시스템 스루풋은 샤드 키shard key 내에서 정렬이 유지되는 한 카프카 클러스터 크기에 선형 비례하여 확장 할 수 있다.
  - 전역 정렬이 없다는 점을 한계로 볼 수 있으나 실제 로그와의 상호 작용은 대게 수백, 수천 개의 프로세스에서 일어나므로 이들의 행위를 순서에 따라 나열하는 건 큰 의미가 없다.
  - 대신 각 파티션별로는 확시한 순서가 유지되기 때문에 카프카에서 같은 송신자로부터 전송된 메시지는 반드시 전송된 순서 그대로 특정 파티션에 추가된다.

- 읽기/쓰기를 한꺼번에 처리하여 쓰루풋을 최적화
  - 로그는 파일 시스템과 같아서 선형적인 읽기/쓰기 패턴을 최적화하기 쉽다.
  - 작은 읽기/쓰기를 묶어서 더욱 큰 규모의 대용량 처리 프로세스로 통합할 수 있다.
  - 카프카는 이러한 최적화를 아주 공격적으로 수행
  - 클라이언트에서 서버 바향으로 데이터를 보내거나 디스크에 쓸 때, 서버 간 복제가 이루어지거나 사용자에게 데이터가 전소될 때, 커밋된 데이터 수신을 확인하는 과정은 배치로 처리
- 불필요한 '데이터 복사' 제거
  - 카프카는 인-메모리in-memory 로그, 온-디스크on-disk 로그, 인-네트워크in-network 데이터의 전송 과정에서 유지되는 간단한 바이너리binary 포맷을 사용한다. 비복사 데이터 전송zero-copy data transfer 등 여러 가지 최적화 기법을 활용 할 수 있다.

이러한 최적화를 되풀이 하면 메모리를 월등이 초과하는 데이터 세트를 유지한 상태에서 디스크나 네트워크에서 지원 가능한 속도로 읽기/쓰기를 할 수 있다.

예로 싱글 스레드가 100 바이트 메시지를 초당 750k 속도로 쓰면서 삼중으로 복제하는 것도 가능(읽기는 더 빨라서 초당 900k 가능)
> [벤치마크](https://engineering.linkedin.com/kafka/benchmarking-apache-kafka-2-million-writes-second-three-cheap-machines)
